{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dnwXZXqWeTv_"
   },
   "outputs": [],
   "source": [
    "!pip install -q openai pinecone langchain langchain-community langchain-openai langchain-pinecone transformers datasets tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import time\n",
    "from pinecone import Pinecone as PineconeClient, ServerlessSpec"
   ],
   "metadata": {
    "id": "CFfJYDoku4S3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ],
   "metadata": {
    "id": "D570bogX_tc6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "OPENAI_API_KEY = getpass(\"Enter your OpenAI API key: \")\n",
    "PINECONE_API_KEY = getpass(\"Enter your Pinecone API key: \")\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY"
   ],
   "metadata": {
    "id": "zYlY0y-wvRuc"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "\n",
    "print('Please upload your business data file (e.g., .txt, .md).')\n",
    "uploaded = files.upload()\n",
    "\n",
    "if not uploaded:\n",
    "    raise ValueError('No file was uploaded. Please run the cell again.')\n",
    "\n",
    "# Get the content of the uploaded file\n",
    "file_name = next(iter(uploaded))\n",
    "business_data_content = uploaded[file_name].decode('utf-8')\n",
    "\n",
    "print(f'Successfully uploaded {file_name}.')"
   ],
   "metadata": {
    "id": "K4SRXr9C3hWx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# The name of the file that the RAG system will read from\n",
    "rag_file_name = \"business_data.txt\"\n",
    "with open(rag_file_name, \"w\") as f:\n",
    "    f.write(business_data_content)"
   ],
   "metadata": {
    "id": "z8g_X9uB31Wa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loader = TextLoader(f'./{rag_file_name}')\n",
    "documents = loader.load()"
   ],
   "metadata": {
    "id": "I29nz0Et4XQx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)"
   ],
   "metadata": {
    "id": "F_Rmsjn14a-X"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
   ],
   "metadata": {
    "id": "7df7CR9s4fRM"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "pc = PineconeClient(api_key=PINECONE_API_KEY)\n",
    "index_name = \"rag-qa-bot-business\"\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    print(f\"Creating a new index: {index_name}\")\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=1536,\n",
    "          metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws',\n",
    "            region='us-east-1'\n",
    "        )\n",
    "    )\n",
    "    time.sleep(1)\n",
    "    print(\"Index created.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' is already there.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HNzbM_uWA-b7",
    "outputId": "b59d7c43-a68c-4c21-fb01-677a1f894b7f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Index 'rag-qa-bot-business' is already there.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "index = pc.Index(index_name)\n",
    "\n",
    "docsearch = PineconeVectorStore(\n",
    "    index=index,\n",
    "    embedding=embeddings,\n",
    "    text_key='text'\n",
    ")\n",
    "\n",
    "docsearch.add_documents(docs)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1aExbPlIBWvP",
    "outputId": "9cf1eca9-90da-465e-a013-9738c317efef"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['8307185e-4ce8-4355-a886-531672ae8239',\n",
       " '1c0e7b61-b0f2-48d7-9b7e-51da6db5f79b']"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=docsearch.as_retriever(),\n",
    "    return_source_documents=True\n",
    ")"
   ],
   "metadata": {
    "id": "uShOnxicBl7L"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def ask_question(query):\n",
    "  result = qa_chain.invoke({\"query\": query})\n",
    "  print(\"\\nANSWER:\")\n",
    "  print(result[\"result\"])\n",
    "  print(\"\\nSOURCES:\")\n",
    "  for source in result[\"source_documents\"]:\n",
    "        print(\"  Source: \" + source.page_content[:160])\n",
    "  print(\"_________________________________\")\n",
    "\n",
    "\n",
    "user_input = input(\"Question: \")\n",
    "\n",
    "if user_input:\n",
    "    ask_question(user_input)\n",
    "else:\n",
    "    print(\"No question was entered.\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIvlKbxrDupk",
    "outputId": "3fb82f34-c663-4ee2-dcf2-d22c7e738d5f"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Question: Where is the office located?\n",
      "\n",
      "ANSWER:\n",
      "InnovateTech Solutions has its headquarters in San Francisco, California, with satellite offices in Austin, Texas, and Bangalore, India.\n",
      "\n",
      "SOURCES:\n",
      "  Source: InnovateTech Solutions - Company FAQ\n",
      "\n",
      "1. What is InnovateTech Solutions?\n",
      "InnovateTech Solutions is a leading provider of custom software development, cloud comp\n",
      "  Source: InnovateTech Solutions - Company FAQ\n",
      "\n",
      "1. What is InnovateTech Solutions?\n",
      "InnovateTech Solutions is a leading provider of custom software development, cloud comp\n",
      "  Source: InnovateTech Solutions - Company FAQ\n",
      "\n",
      "1. What is InnovateTech Solutions?\n",
      "InnovateTech Solutions is a leading provider of custom software development, cloud comp\n",
      "  Source: 4. How can I get a quote for a project?\n",
      "To get a quote, please visit our website's \"Contact Us\" page and fill out the project inquiry form. Our solutions team w\n",
      "_________________________________\n"
     ]
    }
   ]
  }
 ]
}